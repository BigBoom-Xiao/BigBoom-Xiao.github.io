
# 偏差方差权衡

**偏差**：描述的是预测值（估计值）的期望与真实值之间的差距。偏差越大，越偏离真实数据，如下图第二行所示。

**方差**：描述的是预测值的变化范围，离散程度，也就是离其期望值的距离。方差越大，数据的分布越分散，如下图右列所示。

![bias and variance](..\assets\img\PolynomialRegression\bias-and-variance.png)

方差，是形容数据分散程度的，算是“无监督的”，客观的指标，偏差，形容数据跟我们期望的中心差得有多远，算是“有监督的”，有人的知识参与的指标。

## 模型误差

模型误差 = 偏差（Bias） + 方差（Variance） + 不可避免的误差

**导致偏差的主要原因**：

对问题本身的假设不正确！

如：非线性数据使用线性回归

最主要的原因：欠拟合underfitting

其他原因：使用的特征和目标高度不相关

**导致方差的主要原因**：

数据的一点点扰动都会较大的影响模型。

通常原因：使用的模型太复杂，过拟合。

如高阶多项式回归。

## 偏差和方差

有一些算法天生是高方差的算法。如kNN。

非参数学习通常都是高方差算法。因为不对数据进行任何假设。

有一些算法天生是高偏差的算法。如线性回归。

参数学习通常都是高偏差算法。因为对数据具有极强的假设。

大多数算法具有相应的参数，可以调整偏差和方差。

如：

kNN 中的 k ；

线性回归中使用多项式回归。

**偏差和方差通常是矛盾的**

**降低偏差，会提高方差**

**降低方差，会提高偏差**

机器学习的主要挑战，来自于方差！（算法层次）

**解决高方差的通常手段**：

1. 降低模型复杂度
2. 减少数据维度、降噪
3. 增加样本数
4. 使用验证集
5. 模型正则化
