# 人工神经网络建模

## 人工神经元模型

关于神经元的信息处理机制，最早提出也是影响最大的的是 M-P 模型。目前广泛应用的神经元模型，在简化的基础上提出以下六点假设：

1. 每个神经元都是多输入单输出的信息处理单元；
2. 神经元输入分兴奋输入和抑制输入两种类型；
3. 神经元具有空间整合性和阈值特性；
4. 神经元输入和输出间有固定的时间迟滞，主要取决于突触延搁；
5. 忽略时间整合作用和不应期；
6. 神经元本身是非时变的，即其突触时延和突触强度均为常数。

### 神经元数学模型

上述内容可用一个数学表达式进行抽象和概括。令 $ x_i(t) $ 表示 t 时刻神经元 j 接受的来自神经元 i 的输入信息， $ o_j(t) $ 表示 t 时刻神经元 j 的输出信息，则神经元 j 的状态可表达为：

$$ o_j(t) = f\{ [ \sum_{i=1}^n w_{ij} x_i (t - \tau_{ij}) ] - T_j \} $$

式中：

$ \tau_{ij} $ —— 输入和输出间突触时延；

$ T_j $ —— 神经元 j 的阈值；

$ w_{ij} $ —— 神经元 i 到 j 的突触连接系数或者说权重；

$ f(\phi) $ —— 神经元激活函数；

简单起见，突触时延取单位时间，则：

$$ o_j(t + 1) = f\{ [ \sum_{i=1}^n w_{ij} x_i (t) ] - T_j \} $$

其中输入的下表 i 和 输出 o 体现了上述第一点“多输入单输出”，权重值 $ w_{ij} $ 的正负性体现了第二点的输入“兴奋和抑制”，$ T_j $ 体现第三点的阈值；“输入总和”常称为神经元在t时刻的净输入，记作：

$$ net'_j(t) = \sum_{i=1}^n w_{ij} x_i (t) $$

净输入体现了第三点的“空间整合”特性，而未考虑时间整合，当 $ net'_j(t) - T_j > 0 $ 时，神经元才能被激活。 $ o_j(t + 1) $ 和 $ x_i (t) $ 之间的单位时间差意味着所有神经元具有相同的、恒定的工作节律，对应于假定第四点的“突触延搁”； $ w_{ij} $ 与时间的无关体现了假定第六点中神经元的“非时变”。

#### 化简

为了简便起见，我们将公式中的 (t) 省略，还可以将净输入表示为权值向量和输入向量的点击（矩阵化）：

$$ net'_j = W_j^T X $$

其中 $ W_j $ 为权值向量， X 为输入向量，定义为：

$$ W_j = (w_{1j}, w_{2j}, w_{3j}, \dots , w_{nj})^T $$

$$ X = (x_1, x_2, x_3, \dots , x_n)^T $$

如果令 $ x_0 = -1, w_{0j} = T $，则 $ -T_j = x_0 w_{0j} $，因此：

$$ net'_j - T_j = net_j = \sum_{i = 0}^n w_{ij}x_i = W_j^T X $$

之前的式子中，列向量 $ W_j $ 和 X 的第一个分量的下标均是从 1 开始的，而在上式中下标是从 0 开始的。采用上述约定后，净输入改写为 $ net_j $，与原来的区别是包含了阈值。综合以上式，神经元可简化为：

$$ o_j = f(net_j) = f(W_j^T X) $$

### 神经元的激活函数

神经元的各种不同数学模型主要区别在于采用了不同的激活函数，从而使神经元具有不同的神经处理特性。神经元的信息处理特性是决定人工神经网络整体性能的三大要素之一，因此激活函数具有重要的研究意义。最常用的转移函数有一下四种形式：

（1）阈值型激活函数：一般常用的又两种，单极性阈值激活函数，双极性阈值激活函数（符号函数），定义如下：

单极性阈值激活函数：

$$ f(x) = \left\{
\begin{aligned}
1  (x \geq 0) \\
0  (x < 0)
\end{aligned}
\right. $$

双极性阈值激活函数：

$$ sgn(x) = \left\{
\begin{aligned}
1  (x \geq 0) \\
-1  (x < 0)
\end{aligned}
\right. $$

这是神经元模型中常用的一种，许多处理离散信号的神经网络采用符号函数为激活函数。

阈值型激活函数中，自变量 x 为 $ net'_j - T_j $ ，即当 $ net'_j \geq T_j $ 时神经元为兴奋，输出为1，其他情况为抑制，输出 0 或者 -1。

（2）非线性激活函数 非线性激活函数为实数域 R 到 [0, 1] 闭集的非减连续函数，代表了状态连续型神经元模型。最常用的非线性激活函数是单极性的 Sigmoid 函数。简称 S 型函数，其特点是函数本身及其导数都是连续的，因此在处理上十分方便。

单极性 S 型函数定义为：

$$ f(x) = \frac{1}{1 + e^{-x}} $$

有时也使用双极性的 S 型函数，其定义为：

$$ f(x) = \frac{2}{1 + e^{-x}} - 1 = \frac{1 - e^{-x}}{1 + e^{-x}} $$

（3）分段线性激活函数：该函数的特点是神经元的输入和输出在一定区间内满足线性关系。由于其特点因为在实现上比较简单，这类函数也被称为为线性函数。单极性分段函数的表达式如下：

$$ f(x) = \left\{
\begin{aligned}
0  (x \leq 0) \\
cx (0 < x \leq x_c) \\
1  (x_c < x)
\end{aligned}
\right. $$

（4）概率型激活函数：采用此种激活函数的神经元模型的输入和输出之间的关系是不确定的，需要一个随机函数来描述其输出状态为 1 或者为 0 的概率。设神经元输出为 1 的概率为：

$$ P(1) = \frac{1}{1 + e^{-x/T}} $$

式子中，T称为温度参数。由于采用该激活函数的神经元输出状态分布和热力学中的莫尔兹曼分布类似，因此这种神经元模型也成为热力学模型。

## 人工神经网络模型

人工神经网络模型有很多，可以按照不同的方法进行分类。其中最常见的两种分类方法是：按网络连接的拓扑结构分类和按网络内部的信息流分类。

### 网络拓扑结构类型

#### 层次型结构

具有层次结构的神经网络将神经元按功能分成若干层，如输入层、中间层（隐层）和输出层，各层顺序相连。输入层各个神经元负责接收来自外界的输入信息，并传递给中间各隐层神经元；隐层是神经网络的内部信息处理层，负责信息的变换，根据信息变换能力的需要，隐层可以设计为一层或者多层；最后一个隐层传递到各输出层各个神经元的信息进行进一步处理后即完成一次信息处理，由输出层向外界输出信息处理结果。层次网络结构有三种典型结合方式：

（1）单纯型层次网络结构

![单纯型层次网络结构](..\assets\img\20190909\ccwljg.PNG)

神经元分层排列，各层神经元接收前一层输入并输出到下一层，层内神经元自身以及神经元之间不存在连接通路。

（2）输出层到输入层有链接的层次网络结构

![输出层到输入层有链接的层次网络结构](..\assets\img\20190909\iocon.PNG)

输入层神经元既可以接收输入，也具有信息处理能录。

（3）层内有互连的层次网络结构

![层内有互连的层次网络结构](..\assets\img\20190909\coninlay.PNG)

在同一层内引入神经元间的侧向作用，使得能同时激活的神经元个数可控，以实现各层神经元的自组织。

#### 互联型结构

对于互联型网络结构，网络中任意两个节点之间都可能存在连接路径，因此可以根据网络节点中的互联程度将互联型网络结构细分成三种情况：

（1）全互联型 网络中每个节点均与其他所有节点连接。

![全互联型](..\assets\img\20190909\ac.PNG)

（2）局部互联型 网络中每个节点只与其邻近的节点有连接。

![局部互联型](..\assets\img\20190909\pc.PNG)

（3）稀疏连接型 网络中只有少数相距较远的节点相连。

### 网络信息流向类型

根据神经网络内部信息传递的方向来分。

#### 前馈型网络

单纯前馈型网络的结构特点与上图中所示的分层网络完全相同，前馈是因网络信息处理的方向是从输入层到各隐层再到输出层逐层进行而得名。从信息处理能力看，网络中的节点可分为两种：一种是输入节点，只负责从外界引入信息后向前传递给第一隐层；另一种是具有处理能力的节点，包括各隐层和输出层节点。前馈网络中除输出层外，任一层的输出是下一层的输入，信息的处理具有逐层传递进行的方向性，一般不存在反馈环路。因此这类网络很容易串联起来建立多层前馈网络。
多层前馈网络可用一个有向无环路的图表示。其中输人层常记为网络的第一层，第一个隐层记为网络的第二层，其余类推。所以，当提到具有单层计算神经元的网络时，指的应是一个两层前馈网络（输入层和输出层）'当提到具有单隐层的网络时，指的应是一个三层前馈网络（输入层、隐层和输出层）。

#### 反馈型网络

## 建模流程（工程实践）

1. 选取适当的神经网络类型
2. 对权值赋予初始值
3. 选择一定的学习规则对模型进行迭代
4. 最终收敛到合适的权重，确定模型
5. 模型泛化
