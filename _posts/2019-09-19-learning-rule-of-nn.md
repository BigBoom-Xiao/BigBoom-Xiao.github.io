# 神经网络学习

关于学习，可定义为：根据与环境的相互作用二发生的行为改变，其结果倒置对外界刺激产生反映的新模式的建立。

学习过程离不开训练，学习过程就是一种训练使得个体在行为上产生较为持久的改变的过程。

神经网络的全体连接权值可以用一个矩阵W表示，其整体反映了神经网络对于所解决问题的只是存储。神经网络能够通过对样本的学习训练，不断改变网络连接权值以及拓扑结构，以使网络的输出无线接近期望的输出。这一过程被称为神经网络的学习或训练，其本质是可变权值的动态调整。

神经网络的学习算法很多，改变权值的规则都可以称之为学习算法。根据一种广泛的分类方法，可归纳为三类：一类是有监督学习，一类是无监督学习，一类是灌输式学习。

## 三类学习规则

### 监督学习

这种学习方式采用的是纠错规则。学习训练过程中需要不断给网络成对的提供一个输入模式和一个期望网络正确输出的模式，称为“标签”（标签信号、教师信号等）。将神经网络的实际输出同期望输出进行比较，当网络输出与期望的标签不符时，根据差错的方向和大小按照一定的规则调整权值，以使下一步网络输出更接近期望。

### 无监督学习

学习过程中需要不断地给网络提供动态输入信息，网络能根据特有的内部结构和学习规则，在输入信息流中发现热河可能存在的模式和规律，同时能根据网络的功能和输入信息调整权值，这个过程称为网络的自组织，其结果是使网络能对属于同一类的模式进行**自动分类**。这种学习模式中，网络权值的调整不取决于外来的标签，可以认为网络学习评价标准隐含于网络内部或者数据样本之间。

在所解决问题的先验信息很少，甚至没有的时候，这种学习就显得更有实际意义。

### 灌输式学习

指先将网络设计成能记忆特别的例子，以后当给定相关例子的输入信息时，例子便被回忆起来。灌输式学习的权值一旦设计好就不再变动，因此许威西是一次性的，而不是训练过程。

## 网络的训练和神经元的学习

网络的运行一般分为训练和工作两个阶段。训练阶段是为了从训练数据中提取隐含的知识和规律，并储存于网络中供工作中使用。

神经元的学习见[2019-08-28-Learning-rule-of-Prceptor.md](/blog/Learning-rule-of-Prceptor)

## 常见学习规则

### Hebb 学习规则

1949 年心理学家 D.O.Hebb 最早提出了关于神经网络学习机理的“突触修正”的假设。该假设指出，当神经元的突触前膜电位和后膜电位同时为正时，突触传导增强，当前膜电位和后膜电位正负相反时，突触传导减弱。也就是说，当神经元 i 和神经元 j 同时出于兴奋状态时，两者之间的连接强度应增强。根据该假设定义权值的方法，称为 Hebb 学习规则。

在 Hebb 学习规则中，学习信号简单地等于神经元输出：

$$ r = f(W_j^T X) $$

权值向量调整公式为：

$$ \Delta W_j = \eta f(W_j^TX)X $$

权值向量中，每个分量调整由下式确定：

$$ \Delta w_{ij} = \eta f(W_j^TX) x_i = \eta o_j x_i \quad \quad (i = 0, 1, \dots, n) $$

上式表明，权值调整量和输入输出的乘积成正比。显然，经常出现的输入模式将对权值向量又最大的影响。在这种情况下，Heeb学习规则需要预先设置前置的饱和值，以防止输入和输出正负始终一致时出现权值无约束增长。

此外，要求权值初始化，即在学习开始前（t = 0），先对 $ W_j(0) $ 赋予零附近的小随机数。

Hebb 学习规则是一种**纯前馈、无监督学习**。

### Perceptron 学习规则

### $\delta$ 学习规则

### LMS 学习规则

### Correlation 学习规则

### Winner-Take-All 学习规则

### Outstar 学习规则
